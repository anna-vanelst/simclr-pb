{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set your experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "exp_name = \"Test\"\n",
    "config = {\n",
    "         \"prior_type\": \"prob\",\n",
    "         \"temperature\": 0.2, \n",
    "         \"batch_size\": 250,\n",
    "         \"perc_prior\": 0.8,\n",
    "         \"alpha\":0.4,\n",
    "         \"data_name\":\"mnist\",\n",
    "         \"prior_epochs\": 1,\n",
    "         \"learning_rate_prior\": 0.5, \n",
    "         \"momentum_prior\": 0.9,\n",
    "         \"sigma_prior\": 0.01,\n",
    "         \"posterior_epochs\": 1,\n",
    "         \"learning_rate\": 0.1,\n",
    "         \"momentum\": 0.8,\n",
    "         \"kl_penalty\": 1,\n",
    "         \"objective\": \"fclassic\",\n",
    "         \"mc_samples\": 1\n",
    "         }\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(f\"Init Experiment {exp_name} with settings:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split train, test, prior, posterior dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_train_test, data_transform, SimCLRAugmentedDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "data_name = config[\"data_name\"]\n",
    "perc_prior = config[\"perc_prior\"]\n",
    "transform = None\n",
    "train, test = load_train_test(name=data_name, transform=transform)\n",
    "prior_size = int(perc_prior * len(train))\n",
    "posterior_size = len(train) - prior_size\n",
    "prior_dataset, posterior_dataset = random_split(train, [prior_size, posterior_size])\n",
    "print(f\"Size test {len(test)} | Size prior {len(prior_dataset)} | Size posterior {len(posterior_dataset)}\")\n",
    "dataset_list = [train, test, prior_dataset, posterior_dataset]\n",
    "augmented_dataset_list = [SimCLRAugmentedDataset(dataset, name=data_name) for dataset in dataset_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train prior and posterior models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import ExperimentRunner\n",
    "\n",
    "exp_runner = ExperimentRunner(config)\n",
    "prior_type = config[\"prior_type\"]\n",
    "print(f\"Starting training of the {prior_type} prior\")\n",
    "if prior_type == \"det\":\n",
    "    exp_runner.train_prior(prior_dataset)\n",
    "elif prior_type == \"prob\":\n",
    "    exp_runner.train_prob_prior(prior_dataset)\n",
    "print(f\"Starting training of the posterior using the learned {prior_type} prior\")\n",
    "exp_runner.train_posterior(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute risk certificate using the augmented posterior dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_runner.risk_cert.forward(net=exp_runner.posterior_model, augmented_dataset=augmented_dataset_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute test losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_contrastive_loss\n",
    "from loss import ZeroOneLoss, SimplifiedContrastiveLoss, ContrastiveLoss\n",
    "\n",
    "device = exp_runner.device\n",
    "temperature =  config[\"temperature\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "list_contrastive_loss = [ZeroOneLoss(), SimplifiedContrastiveLoss(temperature=temperature)]\n",
    "list_loss_names = [\"Contrastive zero-one Loss\", \"Simplified contrastive loss\"]\n",
    "list_dataset_names = [\"train\", \"test\", \"prior\", \"posterior\"]\n",
    "for idx in [0, 1]:\n",
    "    augmented_dataset = augmented_dataset_list[idx]\n",
    "    name = list_dataset_names[idx]\n",
    "    augmented_loader = torch.utils.data.DataLoader(\n",
    "    augmented_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Metrics for the {name} dataset:\")\n",
    "    for contrastive_loss, loss_name in zip(list_contrastive_loss, list_loss_names):\n",
    "        loss_value = evaluate_contrastive_loss(exp_runner.posterior_model, augmented_loader, contrastive_loss, device)\n",
    "        print(f\"\\u2001 -{loss_name}: {loss_value:.4f}\")\n",
    "        if loss_name== \"Simplified contrastive loss\" and name==\"train\":\n",
    "            save_loss_value = loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_classifier import LinearClassifier\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_name = config[\"data_name\"]\n",
    "num_epochs = 1\n",
    "transform = data_transform(data_name=data_name)\n",
    "train_sup, test_sup = load_train_test(name=data_name, transform=transform)\n",
    "test_loader = DataLoader(test_sup, batch_size=250, shuffle=False)\n",
    "train_loader = DataLoader(train_sup, batch_size=250, shuffle=True)\n",
    "\n",
    "projection_options = [False, True]\n",
    "for projection in projection_options:\n",
    "    print(f\"Linear classifier {'with' if projection else 'without'} projection head\")\n",
    "    model = LinearClassifier(exp_runner.posterior_model, projection=projection, data_name=data_name).to(exp_runner.device)\n",
    "    model.train_classifier(train_loader, num_epochs=num_epochs, lr=0.01)\n",
    "    model.test_classifier(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Compute bound on downstream classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer_bound import Sigma, Bound\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "temperature =  config[\"temperature\"]\n",
    "m = config[\"batch_size\"]\n",
    "neg_samples = m-1\n",
    "sigma = Sigma()\n",
    "transform = data_transform(data_name=data_name)\n",
    "train_sup, test_sup = load_train_test(name=data_name, transform=transform)\n",
    "train_loader = DataLoader(train_sup, batch_size=250, shuffle=True)\n",
    "sigma_value = sigma.forward(exp_runner.posterior_model, train_loader)\n",
    "bound = Bound(tau=temperature, num_neg_samples=neg_samples)\n",
    "bound_values = [bound.forward(save_loss_value, sigma_value, index=idx) for idx in [1, 2]]\n",
    "print(\"Upper-bounds on the linear classifier loss:\")\n",
    "print(f\"\\u2001 -Bao et al. : {bound_values[0]:.4f}\")\n",
    "print(f\"\\u2001 -Theorem 3 : {np.min(bound_values):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
